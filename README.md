# Introduction

One of the most popular and effective enterprise case-studies which leverage analytics today is log analytics. 
Almost every small and big organization today have multiple systems and infrastructure running day in and day out. 
To effectively keep their business running, organizations need to know if their infrastructure is performing to its maximum potential. 
This involves analyzing system and application logs and maybe even apply predictive analytics on log data. 
The amount of log data is typically massive, depending on the type of organizational infrastructure and applications running on it. 
Gone are the days when we were limited by just trying to analyze a sample of data on a single machine due to compute constraints.
big data processing and open-source analytics frameworks like Spark, we can perform scalable log analytics on 
potentially millions and billions of log messages daily. The intent of this case-study oriented tutorial is to take a 
hands-on approach to showcasing how we can leverage Spark to perform log analytics at scale on semi-structured log data.
